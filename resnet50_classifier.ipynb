{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Coral Classification using ResNet50\n",
        "This notebook trains a ResNet50 model to classify whether an image contains corals or not. The ResNet50 model is a convolutional neural network and is available in the PyTorch library."
      ],
      "metadata": {
        "id": "6fSthYy9LEns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Data\n",
        "The data is available for download through a public link. After downloading, unzip the folder to get access to the data."
      ],
      "metadata": {
        "id": "DCEAqvkhLiCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# Download training and validation set\n",
        "url = 'https://drive.google.com/uc?id=1Gdxb0R8ohGqI4yB4KufWYESl0wIc8r8o'\n",
        "output = 'Data_2022_assignment_COMP3007.zip'\n",
        "gdown.download(url, output)"
      ],
      "metadata": {
        "id": "kaBON7wPK1aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip {output} >/dev/null"
      ],
      "metadata": {
        "id": "iXz82VAvLjGU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download testing set\n",
        "url = 'https://drive.google.com/uc?id=1vc5avjn2lRfnIDC2i7XOq22R70m6UTrH'\n",
        "output = 'Testing_Data_2022.zip'\n",
        "gdown.download(url, output)"
      ],
      "metadata": {
        "id": "I-VSh-99uSOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip {output} >/dev/null"
      ],
      "metadata": {
        "id": "FCfz0_2vuWYm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Directories\n",
        "To access the data, various directories need to be defined. The data directory contains two subdirectories that correspond to the training and validation set. The test data directory contains the testing set."
      ],
      "metadata": {
        "id": "bOp0AT5lMiHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Train and valid directories\n",
        "DATA_PATH = os.path.join('Data', 'coral image classification')\n",
        "TRAIN_PATH = os.path.join(DATA_PATH, 'train')\n",
        "VALID_PATH = os.path.join(DATA_PATH, 'val')\n",
        "\n",
        "# Test directory\n",
        "TEST_PATH = os.path.join('TestData', 'CoralImageClassification')"
      ],
      "metadata": {
        "id": "h8vHNbhWL1qO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Epoch\n",
        "An epoch defines a complete pass of the training set that the model sees. During an epoch, the model will attempt to learn the best feature representation to correctly classify data. This learning of features is done with the help of two functions: the loss function and the optimizer. The loss function tells the model how far the predictions are to the ground truth. Based on the loss value, the model will accordingly update its parameters with the help of the optimizer, who calculates the gradients of the model's parameters to minimize the loss function.\n",
        "\n",
        "At the end of each epoch, the model is evaluated with a validation set. During this phase, there is no optimization. The loss value and the accuracy of the model on the validation set will be calculated. The result determines how well the model is performing.\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
      ],
      "metadata": {
        "id": "icz70veCQv_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# An epoch runner\n",
        "def run_epoch(model, criterion, optimizer, data_loader, mode='train'):\n",
        "  # Set the model to training or evaluation mode\n",
        "  if mode == 'train':\n",
        "    model.train()\n",
        "  else:\n",
        "    model.eval()\n",
        "  \n",
        "  # Empty tensors to store the ground truth and predictions\n",
        "  y_true = torch.zeros(0, dtype=torch.long, device='cpu')\n",
        "  y_pred = torch.zeros(0, dtype=torch.long, device='cpu')\n",
        "\n",
        "  # Variables to keep track of the epoch loss\n",
        "  total_loss = 0\n",
        "  total_data = 0\n",
        "\n",
        "  # Check if GPU is available\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  # Iterate through each batch\n",
        "  with tqdm(data_loader, desc=mode) as iterator:\n",
        "    for inputs, labels in iterator:\n",
        "      # Pass the data and ground truth to the GPU if available\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      # Zero out old gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Calculate gradient only for training\n",
        "      with torch.set_grad_enabled(mode == 'train'):\n",
        "        # Get the values from the fully-connected layer of the model\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate the loss function\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Get the predictions\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Keep track of the ground truth and predictions\n",
        "        y_true = torch.cat([y_true, labels.view(-1).cpu()])\n",
        "        y_pred = torch.cat([y_pred, preds.view(-1).cpu()])\n",
        "      \n",
        "        # Update the model's parameters during training\n",
        "        if mode == 'train':\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      # Calculate the epoch loss  \n",
        "      total_loss += loss.item() * inputs.size(0)\n",
        "      total_data += inputs.size(0)\n",
        "\n",
        "      # Keep track of the loss and accuracy\n",
        "      metrics = {\n",
        "          'loss': total_loss / total_data,\n",
        "          'accuracy': accuracy_score(y_true, y_pred)\n",
        "      }\n",
        "\n",
        "      # Display the metrics\n",
        "      iterator.set_postfix(metrics)\n",
        "  \n",
        "  # Display the classification report during evaluation\n",
        "  if mode != 'train':\n",
        "    print('\\n', classification_report(y_true, y_pred, target_names=['No Coral', 'Coral']))\n",
        "  \n",
        "  return metrics['loss'], metrics['accuracy']"
      ],
      "metadata": {
        "id": "h_SwxGsYMmgf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset and Data Loader\n",
        "This cell creates the training, validation, and testing sets from the dataset. Preprocessing is also done according to the original ResNet50 settings. This includes a resizing of the image to a dimension of 224x224 pixels as well as image normalization.\n",
        "\n",
        "To load the dataset for training and evaluation, three data loaders have been created. All data loaders have a batch size of 8."
      ],
      "metadata": {
        "id": "7PCTa4A5VDnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Create the training, validation, and testing sets\n",
        "train_dataset = datasets.ImageFolder(TRAIN_PATH, transform=transform)\n",
        "valid_dataset = datasets.ImageFolder(VALID_PATH, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(TEST_PATH, transform=transform)\n",
        "\n",
        "# Create the training, validation, and testing loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False, num_workers=os.cpu_count(), pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=os.cpu_count(), pin_memory=True)"
      ],
      "metadata": {
        "id": "YrJBAKsvRfLb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization\n",
        "This cell downloads a pre-trained ResNet50 model from the PyTorch library. The model comes with pre-trained weights after being trained on the ImageNet dataset. Minor modification is done on the last layer to match two two labels of this task: coral vs no coral.\n",
        "\n",
        "Cross-entropy loss will be used as the loss function while stochastic gradient descent is used as the optimizer."
      ],
      "metadata": {
        "id": "EylQcbPKWRY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "from torchvision import models\n",
        "\n",
        "# Check if GPU is available for training\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Download the pre-trained model\n",
        "model = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "RWMRSP6pSZXg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the Model\n",
        "To train the model, a number of hyperparameters have to be defined. As the dataset is relatively easy, there is not much hyperparamter tuning to be done. The following hyperparameters have been chosen:\n",
        "* Epochs: 10\n",
        "* Batch Size: 8\n",
        "* Learning Rate: 0.001\n",
        "* Momentum: 0.9\n",
        "* Image Size: 224\n",
        "\n",
        "After each epoch, the accuracy of the model is evaluated on the validation set. Model selection is done by choosing the epoch where the model has the highest accuracy as long as there is no overfitting or underfitting."
      ],
      "metadata": {
        "id": "fWEY5R8-XQdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of epochs\n",
        "epochs = list(range(10))\n",
        "\n",
        "# Keep track of the training and validation metrics\n",
        "train_losses, train_accuracies = [], []\n",
        "valid_losses, valid_accuracies = [], []\n",
        "\n",
        "# Keep track of the best model\n",
        "best_model = None\n",
        "best_accuracy = 0\n",
        "\n",
        "# Start training\n",
        "for i in epochs:\n",
        "  print('Epoch', i)\n",
        "\n",
        "  # Train and evaluate the model\n",
        "  train_loss, train_accuracy = run_epoch(model, criterion, optimizer, train_loader, mode='train')\n",
        "  valid_loss, valid_accuracy = run_epoch(model, criterion, optimizer, valid_loader, mode='valid')\n",
        "\n",
        "  # Keep track of the training metrics\n",
        "  train_losses.append(train_loss)\n",
        "  train_accuracies.append(train_accuracy)\n",
        "\n",
        "  # Keep track of the validation metrics\n",
        "  valid_losses.append(valid_loss)\n",
        "  valid_accuracies.append(valid_accuracy)\n",
        "\n",
        "  # Update the best model if the accuracy improved\n",
        "  if valid_accuracy > best_accuracy:\n",
        "    best_model = model\n",
        "    best_accuracy = valid_accuracy\n",
        "    print('Improved model updated!\\n')\n",
        "\n",
        "# Save the best model\n",
        "torch.save(model.cpu().state_dict(), 'resnet50.pth')"
      ],
      "metadata": {
        "id": "gnQ02-29TOVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Losses\n",
        "This cell plots the losses of the model on the training and validation set."
      ],
      "metadata": {
        "id": "hQ8RLLrHYwPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from IPython.display import Image\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=epochs, y=train_losses, name='train_loss'))\n",
        "fig.add_trace(go.Scatter(x=epochs, y=valid_losses, name='valid_loss'))\n",
        "fig.update_layout(\n",
        "    title=\"Training vs Validation Loss of ResNet50\",\n",
        "    title_x=0.5,\n",
        "    xaxis_title=\"Epoch\",\n",
        "    yaxis_title=\"Loss\"\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "FvyOK1xvZnHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Accuracies\n",
        "This cell plots the accuracies of the model on the training and validation set."
      ],
      "metadata": {
        "id": "xVknixsVY9Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=epochs, y=train_accuracies, name='train_accuracy'))\n",
        "fig.add_trace(go.Scatter(x=epochs, y=valid_accuracies, name='valid_accuracy'))\n",
        "fig.update_layout(\n",
        "    title=\"Training vs Validation Accuracy of ResNet50\",\n",
        "    title_x=0.5,\n",
        "    xaxis_title=\"Epoch\",\n",
        "    yaxis_title=\"Accuracy\"\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "q-IAr9k2YaEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate a Trained ResNet50 on Test Set\n",
        "The following cells load the weights of an already trained model and evaluate it on the test set."
      ],
      "metadata": {
        "id": "lX__VIpFZBtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1IHNz6za0lRmaVXjG-O50r0eBU9oeCs7u'\n",
        "output = 'resnet50.pth'\n",
        "gdown.download(url, output)"
      ],
      "metadata": {
        "id": "YUM6mBNwge2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the best model\n",
        "model = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "with open('resnet50.pth', 'rb') as f:\n",
        "  model.load_state_dict(torch.load(f))\n",
        "model = model.to(device).eval()"
      ],
      "metadata": {
        "id": "NF7e_Ss1ZxBS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the testing set\n",
        "test_loss, test_accuracy = run_epoch(model, criterion, optimizer, test_loader, mode='test')"
      ],
      "metadata": {
        "id": "mJG8iIvAvdd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify Single Image\n",
        "This cell classifies a single image. The true label and the prediction are both shown."
      ],
      "metadata": {
        "id": "4493zxp4aNRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "\n",
        "# Preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "labels = sorted(os.listdir(TEST_PATH))\n",
        "modified_labels = ['No Coral', 'Coral']\n",
        "true_label = modified_labels[0]\n",
        "\n",
        "# Get the image\n",
        "img_path = os.path.join(TEST_PATH, labels[0], '13-11-41-27_1.1421167342.57-top_right.png')\n",
        "img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "# Preprocess the image\n",
        "data = transform(img).unsqueeze(0)\n",
        "\n",
        "# Get the model's output\n",
        "with torch.no_grad():\n",
        "  output = model(data.to(device))\n",
        "\n",
        "# Process the output to get the prediction\n",
        "img_preds = nn.Softmax(dim=-1)(output)\n",
        "img_preds = img_preds.cpu().numpy().squeeze()\n",
        "img_pred = modified_labels[np.argmax(img_preds)]\n",
        "img_pred_score = np.max(img_preds) * 100\n",
        "\n",
        "print('True: {}'.format(true_label))\n",
        "print('Pred: {} ({:.2f}%)'.format(img_pred, img_pred_score))\n",
        "\n",
        "img = np.array(img)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "cv2_imshow(cv2.resize(img, (256, 256)))"
      ],
      "metadata": {
        "id": "nBhBpsv_aOce"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}